{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c44ff9-0a4f-4100-808b-5b9edf6578ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0425bb-1bc0-4362-add6-a4a9a2203dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae8af-10e4-4963-a4eb-051369b60ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/MachineLearningRating_v3.txt\", sep=\"|\")\n",
    "\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c337f-8f4e-4173-afda-0695456d1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe(include='all')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2869d4-924c-4780-91db-1e20729f81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TransactionMonth to datetime\n",
    "df[\"TransactionMonth\"] = pd.to_datetime(df[\"TransactionMonth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f50600-3f12-42bf-bd48-1bf1ce425f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"CrossBorder\", \"NumberOfVehiclesInFleet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf89f7c-bcb5-40dd-a44e-57871ce29d3f",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426d4298-1f6c-48e0-b3a5-f43ad427ccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(779642)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values before applying ML model to hanldle it\n",
    "df['CustomValueEstimate'].isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a13a6e0-7961-49db-be2a-04923eb00448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# # Features that are useful for predicting\n",
    "# features = [\n",
    "#     'make', 'Province', 'RegistrationYear', 'SumInsured',\n",
    "#     'kilowatts', 'cubiccapacity', 'bodytype'\n",
    "# ]\n",
    "\n",
    "# # Split into rows with and without missing CustomValueEstimate\n",
    "# df_train = df[df['CustomValueEstimate'].notnull()]\n",
    "# df_missing = df[df['CustomValueEstimate'].isnull()]\n",
    "\n",
    "# # Sample dataset to train (only 10,000 rows for training to avoid memory issues)\n",
    "# df_train_sample = df_train.sample(10000, random_state=42)\n",
    "\n",
    "# # Combine both sets \n",
    "# df_all = pd.concat([df_train_sample, df_missing], axis=0)\n",
    "\n",
    "# # One-hot encode the categorical columns\n",
    "# df_encoded = pd.get_dummies(df_all[features])\n",
    "\n",
    "# # Split encoded features back into X_train and X_pred\n",
    "# X_train = df_encoded.iloc[:len(df_train_sample), :]\n",
    "# X_pred = df_encoded.iloc[len(df_train_sample):, :]\n",
    "\n",
    "# # Target variable\n",
    "# y_train = df_train_sample['CustomValueEstimate']\n",
    "\n",
    "# # Train model\n",
    "# model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict missing values\n",
    "# predicted_values = model.predict(X_pred)\n",
    "\n",
    "# # Fill in the missing values in the original dataframe\n",
    "# df.loc[df['CustomValueEstimate'].isnull(), 'CustomValueEstimate'] = predicted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6302887-bab2-4a1a-9e9e-89f27839684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After handling missing values \n",
    "# df['CustomValueEstimate'].isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce76dca-fcba-44bb-a0e2-b526dfa93ce4",
   "metadata": {},
   "source": [
    "### Handling some common missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64efcc15-4bbc-4def-bd40-e07dbeb4b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill common missing values\n",
    "# df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "# df['MaritalStatus'].fillna(df['MaritalStatus'].mode()[0], inplace=True)\n",
    "\n",
    "# df['Bank'].fillna(\"Unknown\", inplace=True)\n",
    "# df['AccountType'].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a0e01-74fc-4377-a0d8-fa31fda485e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7955ac-21a3-489a-84cd-13212146315f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad72880-aae0-4773-ae1a-62a0df0e3979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b034b9-1f18-4a1a-b59c-1d6947c8d715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(779642)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After handling missing values \n",
    "df['CustomValueEstimate'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ec7c24-601d-4520-b610-2732c4df8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fill Simple Columns\n",
    "def fill_simple_values(df):\n",
    "    df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "    df['MaritalStatus'].fillna(df['MaritalStatus'].mode()[0], inplace=True)\n",
    "    df['Bank'].fillna(\"Unknown\", inplace=True)\n",
    "    df['AccountType'].fillna(\"Unknown\", inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Predict Binary Columns\n",
    "def predict_binary_column(df, target_col, features):\n",
    "    print(f\"Imputing {target_col}...\")\n",
    "\n",
    "    # Convert Yes/No to binary\n",
    "    df[target_col] = df[target_col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    # Create subset where target and features are not missing\n",
    "    df_subset = df[features + [target_col]].dropna()\n",
    "\n",
    "    # Split into known and missing\n",
    "    train_data = df_subset[df_subset[target_col].notnull()]\n",
    "    predict_data = df[df[target_col].isnull()]\n",
    "\n",
    "    # One-hot encode features\n",
    "    X = pd.get_dummies(train_data[features])\n",
    "    y = train_data[target_col]\n",
    "\n",
    "    X_pred = pd.get_dummies(predict_data[features])\n",
    "    X_pred = X_pred.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "    # Train classifier\n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict\n",
    "    predicted = model.predict(X_pred)\n",
    "\n",
    "    # Fill predictions back\n",
    "    df.loc[df[target_col].isnull(), target_col] = predicted\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Predict CustomValueEstimate\n",
    "\n",
    "def predict_custom_value(df):\n",
    "    print(\"Imputing CustomValueEstimate...\")\n",
    "\n",
    "    features = [\n",
    "        'make', 'Province', 'bodytype',\n",
    "        'RegistrationYear', 'SumInsured', 'kilowatts', 'cubiccapacity'\n",
    "    ]\n",
    "\n",
    "    # Clean training data\n",
    "    df_train = df[df['CustomValueEstimate'].notnull()].dropna(subset=features)\n",
    "    df_missing = df[df['CustomValueEstimate'].isnull()].dropna(subset=features)\n",
    "\n",
    "    # Save the indexes of rows we're predicting\n",
    "    missing_indexes = df_missing.index\n",
    "\n",
    "    # Sample only 10k rows to avoid memory issues\n",
    "    df_train_sample = df_train.sample(10000, random_state=42)\n",
    "\n",
    "    # Combine for consistent encoding\n",
    "    df_all = pd.concat([df_train_sample[features], df_missing[features]])\n",
    "    df_encoded = pd.get_dummies(df_all)\n",
    "\n",
    "    # Split into train and predict sets\n",
    "    X_train = df_encoded.iloc[:len(df_train_sample), :]\n",
    "    X_pred = df_encoded.iloc[len(df_train_sample):]\n",
    "    y_train = df_train_sample['CustomValueEstimate']\n",
    "\n",
    "    # Train model\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    model = RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    predicted = model.predict(X_pred)\n",
    "\n",
    "    # âœ… Assign back using matching indexes\n",
    "    df.loc[missing_indexes, 'CustomValueEstimate'] = predicted\n",
    "\n",
    "    print(\"CustomValueEstimate imputation complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def run_full_imputation(df):\n",
    "    # Fill simple columns\n",
    "    df = fill_simple_values(df)\n",
    "\n",
    "    # Common features to use in all imputations\n",
    "    features = [\n",
    "    'make', 'Province', 'bodytype',\n",
    "    'RegistrationYear', 'SumInsured', 'kilowatts', 'cubiccapacity'\n",
    "]\n",
    "\n",
    "    # Predict binary targets\n",
    "    for col in ['WrittenOff', 'Rebuilt', 'Converted']:\n",
    "        df = predict_binary_column(df, col, features)\n",
    "\n",
    "    # Predict CustomValueEstimate\n",
    "    df = predict_custom_value(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8a7444-d3ad-4bb5-beed-89b88e6026e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28490/2080151920.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
      "/tmp/ipykernel_28490/2080151920.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['MaritalStatus'].fillna(df['MaritalStatus'].mode()[0], inplace=True)\n",
      "/tmp/ipykernel_28490/2080151920.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Bank'].fillna(\"Unknown\", inplace=True)\n",
      "/tmp/ipykernel_28490/2080151920.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['AccountType'].fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing WrittenOff...\n",
      "Imputing Rebuilt...\n",
      "Imputing Converted...\n",
      "Imputing CustomValueEstimate...\n",
      "CustomValueEstimate imputation complete.\n"
     ]
    }
   ],
   "source": [
    "df = run_full_imputation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3935904-919b-4ced-b02b-ba7c17a5a55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(552)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After handling missing values \n",
    "df['CustomValueEstimate'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed8010f-624b-4f4a-b76f-efab8c24c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28490/2085543662.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CustomValueEstimate'].fillna(df['CustomValueEstimate'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Final clean-up after model-based predictions\n",
    "df['CustomValueEstimate'].fillna(df['CustomValueEstimate'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c547f9b0-008c-485a-9718-dd0c2256f4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CustomValueEstimate'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7167df0-338c-4da9-8ae9-e5d559d575f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnderwrittenCoverID              0\n",
       "PolicyID                         0\n",
       "TransactionMonth                 0\n",
       "IsVATRegistered                  0\n",
       "Citizenship                      0\n",
       "LegalType                        0\n",
       "Title                            0\n",
       "Language                         0\n",
       "Bank                             0\n",
       "AccountType                      0\n",
       "MaritalStatus                    0\n",
       "Gender                           0\n",
       "Country                          0\n",
       "Province                         0\n",
       "PostalCode                       0\n",
       "MainCrestaZone                   0\n",
       "SubCrestaZone                    0\n",
       "ItemType                         0\n",
       "mmcode                         552\n",
       "VehicleType                    552\n",
       "RegistrationYear                 0\n",
       "make                           552\n",
       "Model                          552\n",
       "Cylinders                      552\n",
       "cubiccapacity                  552\n",
       "kilowatts                      552\n",
       "bodytype                       552\n",
       "NumberOfDoors                  552\n",
       "VehicleIntroDate               552\n",
       "CustomValueEstimate              0\n",
       "AlarmImmobiliser                 0\n",
       "TrackingDevice                   0\n",
       "CapitalOutstanding               2\n",
       "NewVehicle                  153295\n",
       "WrittenOff                       0\n",
       "Rebuilt                          0\n",
       "Converted                        0\n",
       "SumInsured                       0\n",
       "TermFrequency                    0\n",
       "CalculatedPremiumPerTerm         0\n",
       "ExcessSelected                   0\n",
       "CoverCategory                    0\n",
       "CoverType                        0\n",
       "CoverGroup                       0\n",
       "Section                          0\n",
       "Product                          0\n",
       "StatutoryClass                   0\n",
       "StatutoryRiskType                0\n",
       "TotalPremium                     0\n",
       "TotalClaims                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4904a9ae-f866-4a9f-9da4-7e226f350831",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m categorical_car_cols = [\u001b[33m'\u001b[39m\u001b[33mmake\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbodytype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mVehicleType\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_car_cols:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df[col] = \u001b[43mdf\u001b[49m[col].fillna(\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m numerical_car_cols = [\u001b[33m'\u001b[39m\u001b[33mkilowatts\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcubiccapacity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCylinders\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numerical_car_cols:\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "categorical_car_cols = ['make', 'Model', 'bodytype', 'VehicleType']\n",
    "for col in categorical_car_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "numerical_car_cols = ['kilowatts', 'cubiccapacity', 'Cylinders']\n",
    "for col in numerical_car_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "if df['VehicleIntroDate'].isnull().sum() > 0:\n",
    "    df['VehicleIntroDate'] = df['VehicleIntroDate'].fillna(df['VehicleIntroDate'].mode()[0])\n",
    "\n",
    "df['NewVehicle'] = df['NewVehicle'].fillna('Unknown')\n",
    "\n",
    "df['CapitalOutstanding'] = (\n",
    "    df['CapitalOutstanding']\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \".\")  # comma to dot\n",
    "    .str.replace(r\"[^\\d.]\", \"\", regex=True)  # remove any extra characters\n",
    ")\n",
    "df['CapitalOutstanding'] = pd.to_numeric(df['CapitalOutstanding'], errors='coerce')\n",
    "df['CapitalOutstanding'] = df['CapitalOutstanding'].fillna(df['CapitalOutstanding'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b34fd-43c3-49d7-9b9f-ad487e22b6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
